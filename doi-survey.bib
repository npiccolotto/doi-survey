@article{abello2014,
  title = {A {{Modular Degree-of-Interest Specification}} for the {{Visual Analysis}} of {{Large Dynamic Networks}}},
  author = {Abello, James and Hadlak, Steffen and Schumann, Heidrun and Schulz, Hans-Jörg},
  date = {2014-03},
  journaltitle = {IEEE Transactions on Visualization and Computer Graphics},
  volume = {20},
  number = {3},
  pages = {337--350},
  issn = {1941-0506},
  doi = {10.1109/TVCG.2013.109},
  abstract = {Large dynamic networks are targets of analysis in many fields. Tracking temporal changes at scale in these networks is challenging due in part to the fact that small changes can be missed or drowned-out by the rest of the network. For static networks, current approaches allow the identification of specific network elements within their context. However, in the case of dynamic networks, the user is left alone with finding salient local network elements and tracking them over time. In this work, we introduce a modular DoI specification to flexibly define what salient changes are and to assign them a measure of their importance in a time-varying setting. The specification takes into account neighborhood structure information, numerical attributes of nodes/edges, and their temporal evolution. A tailored visualization of the DoI specification complements our approach. Alongside a traditional node-link view of the dynamic network, it serves as an interface for the interactive definition of a DoI function. By using it to successively refine and investigate the captured details, it supports the analysis of dynamic networks from an initial view until pinpointing a user's analysis goal. We report on applying our approach to scientific coauthorship networks and give concrete results for the DBLP data set.},
  eventtitle = {{{IEEE Transactions}} on {{Visualization}} and {{Computer Graphics}}},
  keywords = {Context,Data visualization,degree-of-interest,dynamic graph visualization,Educational institutions,Electronic mail,Navigation,Radiation detectors,Time-varying graphs,Visualization},
  file = {/Users/npiccolotto/Zotero/storage/LFEVN4PH/Abello et al. - 2014 - A Modular Degree-of-Interest Specification for the.pdf;/Users/npiccolotto/Zotero/storage/48YANLME/stamp.html}
}

@inproceedings{bartram1995,
  title = {The Continuous Zoom: A Constrained Fisheye Technique for Viewing and Navigating Large Information Spaces},
  shorttitle = {The Continuous Zoom},
  booktitle = {Proceedings of the 8th Annual {{ACM}} Symposium on {{User}} Interface and Software Technology},
  author = {Bartram, Lyn and Ho, Albert and Dill, John and Henigman, Frank},
  date = {1995-12},
  pages = {207--215},
  publisher = {{ACM}},
  location = {{Pittsburgh Pennsylvania USA}},
  doi = {10.1145/215585.215977},
  url = {https://dl.acm.org/doi/10.1145/215585.215977},
  urldate = {2023-02-23},
  eventtitle = {{{8UIST95}}: 8th {{ACM Symposium}} on {{User Interface}} and {{Software Technology}}},
  isbn = {978-0-89791-709-4},
  langid = {english},
  file = {/Users/npiccolotto/Zotero/storage/8JQ774WQ/Bartram et al. - 1995 - The continuous zoom a constrained fisheye techniq.pdf}
}

@inproceedings{bederson2000,
  title = {Fisheye {{Menus}}},
  booktitle = {Proceedings of the 13th Annual {{ACM}} Symposium on {{User}} Interface Software and Technology},
  author = {Bederson, Benjamin B},
  date = {2000},
  pages = {217--225},
  publisher = {{ACM}},
  location = {{San Diego, California, USA}},
  abstract = {We introduce “fisheye menus” which apply traditional fisheye graphical visualization techniques to linear menus. This provides for an efficient mechanism to select items from long menus, which are becoming more common as menus are used to select data items in, for example, ecommerce applications. Fisheye menus dynamically change the size of menu items to provide a focus area around the mouse pointer. This makes it possible to present the entire menu on a single screen without requiring buttons, scrollbars, or hierarchies.},
  eventtitle = {{{UIST}}},
  langid = {english},
  file = {/Users/npiccolotto/Zotero/storage/V6VT5N6Z/Bederson - Human-Computer Interaction Lab Institute for Advan.pdf}
}

@article{bernard2019a,
  title = {Visual {{Analysis}} of {{Degree-of-Interest Functions}} to {{Support Selection Strategies}} for {{Instance Labeling}}},
  author = {Bernard, Jürgen and Hutter, Marco and Ritter, Christian and Lehmann, Markus and Sedlmair, Michael and Zeppelzauer, Matthias},
  date = {2019},
  journaltitle = {EuroVis Workshop on Visual Analytics (EuroVA)},
  pages = {5 pages},
  publisher = {{The Eurographics Association}},
  doi = {10.2312/EUROVA.20191116},
  url = {https://diglib.eg.org/handle/10.2312/eurova20191116},
  urldate = {2021-04-30},
  abstract = {Manually labeling data sets is a time-consuming and expensive task that can be accelerated by interactive machine learning and visual analytics approaches. At the core of these approaches are strategies for the selection of candidate instances to label. We introduce degree-of-interest (DOI) functions as atomic building blocks to formalize candidate selection strategies. We introduce a taxonomy of DOI functions and an approach for the visual analysis of DOI functions, which provide novel complementary views on labeling strategies and DOIs, support their in-depth analysis and facilitate their interpretation. Our method shall support the generation of novel and better explanation of existing labeling strategies in future.},
  isbn = {9783038680871},
  langid = {english},
  version = {001-005},
  file = {/Users/npiccolotto/Zotero/storage/528AIZAJ/Bernard et al. - 2019 - Visual Analysis of Degree-of-Interest Functions to.pdf}
}

@inproceedings{burns2007,
  title = {Feature {{Emphasis}} and {{Contextual Cutaways}} for {{Multimodal Medical Visualization}}},
  author = {Burns, Michael and Haidacher, Martin and Wein, Wolfgang and Viola, Ivan and Gröller, M Eduard},
  date = {2007},
  pages = {275--282},
  publisher = {{The Eurographics Association}},
  doi = {http://hdl.handle.net/20.500.12708/51949},
  abstract = {Dense clinical data like 3D Computed Tomography (CT) scans can be visualized together with real-time imaging for a number of medical intervention applications. However, it is difficult to provide a fused visualization that allows sufficient spatial perception of the anatomy of interest, as derived from the rich pre-operative scan, while not occluding the real-time image displayed embedded within the volume.},
  eventtitle = {{{EuroVis}}},
  langid = {english},
  file = {/Users/npiccolotto/Zotero/storage/QNFBH3C8/Burns et al. - Feature Emphasis and Contextual Cutaways for Multi.pdf}
}

@inproceedings{card2002,
  title = {Degree-of-Interest Trees: A Component of an Attention-Reactive User Interface},
  shorttitle = {Degree-of-Interest Trees},
  booktitle = {Proceedings of the {{Working Conference}} on {{Advanced Visual Interfaces}}},
  author = {Card, Stuart K. and Nation, David},
  date = {2002-05-22},
  pages = {231--245},
  publisher = {{ACM}},
  location = {{Trento Italy}},
  doi = {10.1145/1556262.1556300},
  url = {https://dl.acm.org/doi/10.1145/1556262.1556300},
  urldate = {2023-01-27},
  abstract = {This paper proposes Degree-of-Interest trees. These trees use degree-of-interest calculations and focus+context visualization methods, together with bounding constraints, to fit within preestablished bounds. The method is an instance of an emerging "attention-reactive" user interface whose components are designed to snap together in bounded spaces.},
  eventtitle = {{{AVI}}'02: {{Advanced Visual Interfaces}}},
  isbn = {978-1-58113-537-4},
  langid = {english},
  file = {/Users/npiccolotto/Zotero/storage/I4TJF4UZ/Card and Nation - 2002 - Degree-of-interest trees a component of an attent.pdf}
}

@inproceedings{carmo2008,
  title = {{{MoViSys}} – {{A Visualization System}} for {{Geo-Referenced Information}} on {{Mobile Devices}}},
  booktitle = {Visual {{Information Systems}}. {{Web-Based Visual Information Search}} and {{Management}}},
  author = {Carmo, Maria Beatriz and Afonso, Ana Paula and Pombinho de Matos, Paulo and Vaz, Ana},
  editor = {Sebillo, Monica and Vitiello, Giuliana and Schaefer, Gerald},
  date = {2008},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  pages = {167--178},
  publisher = {{Springer}},
  location = {{Berlin, Heidelberg}},
  doi = {10.1007/978-3-540-85891-1_20},
  abstract = {Visualization of geo-referenced information on mobile devices can be useful in diverse areas. These applications require a user-friendly interface to enable querying the data interactively and the generation of intelligible images. Moreover, they must deal with the limitations of mobile devices, such as small screen size, and the context of mobility. This paper describes MoViSys, a visualization system for geo-referenced data, organized in several categories with multiple attributes, on mobile devices. This system explores filtering mechanisms to present the result of interactive queries specified through an adaptive interface.},
  isbn = {978-3-540-85891-1},
  langid = {english},
  keywords = {adaptive user interfaces,filtering mechanisms,Geo-referenced information visualization,mobile visual informa-tion systems},
  file = {/Users/npiccolotto/Zotero/storage/I2YMAGDG/Carmo et al. - 2008 - MoViSys – A Visualization System for Geo-Reference.pdf}
}

@article{carvalho2008,
  title = {A Temporal Focus + Context Visualization Model for Handling Valid-Time Spatial Information},
  author = {Carvalho, Alexandre and De Sousa, A. Augusto and Ribeiro, Cristina and Costa, Emília},
  date = {2008-09},
  journaltitle = {Information Visualization},
  shortjournal = {Information Visualization},
  volume = {7},
  number = {3-4},
  pages = {265--274},
  issn = {1473-8716, 1473-8724},
  doi = {10.1057/PALGRAVE.IVS.9500188},
  url = {http://journals.sagepub.com/doi/10.1057/PALGRAVE.IVS.9500188},
  urldate = {2023-01-27},
  abstract = {Spatiotemporal databases provide effective means to represent, manage and query information evolving over time. However, the visualization of record sets that result from spatiotemporal queries through traditional visualization techniques can be of difficult interpretation or may lack the ability to meaningfully display several instants at the same time. We propose a Temporal Focus + Context visualization model to overcome issues from such techniques resorting to concepts from Information Visualization. In this model, Focus + Context is applied to time rather than, as more typically, to attributes or space, and allows large amounts of data from distinct periods of time and from several record sets to be compressed onto one. Underlying the proposed visualization technique is the calculation of a temporal degree of interest (TDOI) for each record driven by specific analysis, exploration or presentation goals and based on the record valid time attribute, as well as on user-defined temporal visualization requirements. In the mapping stage of the visualization pipeline, the TDOI for a record is used to control graphical properties, such as transparency and color. More complex rendering properties, such as sketch drawing edges or other non-photorealistic enhancement techniques, can also be used to convey the temporal aspects of data, replacing the original graphical features of the record data. By enhancing or dimming the representation of a data item, according to the corresponding degree of interest, it is possible to meaningfully compress information about distinct temporal states of data onto the same visualization display. The model has been applied to several test scenarios and proved appropriate and useful for a wide range of domains that require the display, exploration and analysis of spatial information discretely evolving over time.},
  langid = {english},
  file = {/Users/npiccolotto/Zotero/storage/B3LLPIJD/Carvalho et al. - 2008 - A temporal focus + context visualization model for.pdf}
}

@article{chen2022,
  title = {Towards {{Better Caption Supervision}} for {{Object Detection}}},
  author = {Chen, Changjian and Wu, Jing and Wang, Xiaohan and Xiang, Shouxing and Zhang, Song-Hai and Tang, Qifeng and Liu, Shixia},
  date = {2022-04},
  journaltitle = {IEEE Transactions on Visualization and Computer Graphics},
  volume = {28},
  number = {4},
  pages = {1941--1954},
  issn = {1941-0506},
  doi = {10.1109/TVCG.2021.3138933},
  abstract = {As training high-performance object detectors requires expensive bounding box annotations, recent methods resort to free-available image captions. However, detectors trained on caption supervision perform poorly because captions are usually noisy and cannot provide precise location information. To tackle this issue, we present a visual analysis method, which tightly integrates caption supervision with object detection to mutually enhance each other. In particular, object labels are first extracted from captions, which are utilized to train the detectors. Then, the objects detected from images are fed into caption supervision for further improvement. To effectively loop users into the object detection process, a node-link-based set visualization supported by a multi-type relational co-clustering algorithm is developed to explain the relationships between the extracted labels and the images with detected objects. The co-clustering algorithm clusters labels and images simultaneously by utilizing both their representations and their relationships. Quantitative evaluations and a case study are conducted to demonstrate the efficiency and effectiveness of the developed method in improving the performance of object detectors.},
  eventtitle = {{{IEEE Transactions}} on {{Visualization}} and {{Computer Graphics}}},
  keywords = {Annotations,caption supervision,co-clustering,Detectors,interactive visualization,Labeling,Machine learning,Noise measurement,object detection,Object detection,Training,Visualization},
  file = {/Users/npiccolotto/Zotero/storage/QTTS2U4L/Chen et al. - 2022 - Towards Better Caption Supervision for Object Dete.pdf;/Users/npiccolotto/Zotero/storage/ZCQDZ34A/stamp.html}
}

@article{cohe2016,
  title = {{{SchemeLens}}: {{A Content-Aware Vector-Based Fisheye Technique}} for {{Navigating Large Systems Diagrams}}},
  shorttitle = {{{SchemeLens}}},
  author = {Cohé, Aurélie and Liutkus, Bastien and Bailly, Gilles and Eagan, James and Lecolinet, Eric},
  date = {2016-01},
  journaltitle = {IEEE Transactions on Visualization and Computer Graphics},
  volume = {22},
  number = {1},
  pages = {330--338},
  issn = {1941-0506},
  doi = {10.1109/TVCG.2015.2467035},
  abstract = {System schematics, such as those used for electrical or hydraulic systems, can be large and complex. Fisheye techniques can help navigate such large documents by maintaining the context around a focus region, but the distortion introduced by traditional fisheye techniques can impair the readability of the diagram. We present SchemeLens, a vector-based, topology-aware fisheye technique which aims to maintain the readability of the diagram. Vector-based scaling reduces distortion to components, but distorts layout. We present several strategies to reduce this distortion by using the structure of the topology, including orthogonality and alignment, and a model of user intention to foster smooth and predictable navigation. We evaluate this approach through two user studies: Results show that (1) SchemeLens is 16-27\% faster than both round and rectangular flat-top fisheye lenses at finding and identifying a target along one or several paths in a network diagram; (2) augmenting SchemeLens with a model of user intentions aids in learning the network topology.},
  eventtitle = {{{IEEE Transactions}} on {{Visualization}} and {{Computer Graphics}}},
  keywords = {content-aware,Context,Distortion,Fisheye,information visualization,interactive zoom,Layout,Lenses,navigation,Navigation,network schematics,Shape,vector-scaling,Visualization},
  file = {/Users/npiccolotto/Zotero/storage/3UL4QPPU/Cohé et al. - 2016 - SchemeLens A Content-Aware Vector-Based Fisheye T.pdf;/Users/npiccolotto/Zotero/storage/X9FK5GE6/stamp.html}
}

@article{doleisch2006,
  title = {Interactive {{Focus}}+{{Context Analysis}} of {{Large}}, {{Time-Dependent Flow Simulation Data}}},
  author = {Doleisch, Helmut and Hauser, Helwig and Gasser, Martin and Kosara, Robert},
  date = {2006-12-01},
  journaltitle = {SIMULATION},
  volume = {82},
  number = {12},
  pages = {851--865},
  publisher = {{SAGE Publications Ltd STM}},
  issn = {0037-5497},
  doi = {10.1177/0037549707078278},
  url = {https://doi.org/10.1177/0037549707078278},
  urldate = {2023-01-24},
  abstract = {The visualization of time-dependent simulation data, such as data sets from computational fluid dynamics (CFD) simulation, is still a very challenging task. In this paper, we present a new approach for the interactive visual analysis of flow simulation data, which is especially targeted at the analysis of time-dependent data. This supports the flexible specification and visualization of flow features in an interactive setup of multiple linked views. Special emphasis is put on new mechanisms to capture time-dependent features (i.e. flow features that are inherently dependent on time). We propose the integration of attribute derivation into the process of interactive visual analysis to enable the subsequent user access to otherwise implicit properties of the unsteady data in our interactive feature specification framework. All views of this flow analysis setup are linked, in the sense that the features in focus are consistently emphasized in the visualization (more colorful, less transparent) whereas the rest of the data are only shown as context in reduced style. In addition to introducing our new approach, we also demonstrate its use in the context of several application examples.},
  langid = {english},
  file = {/Users/npiccolotto/Zotero/storage/ID5E9FIG/Doleisch et al. - 2006 - Interactive Focus+Context Analysis of Large, Time-.pdf}
}

@article{furnas1986,
  title = {Generalized Fisheye Views},
  author = {Furnas, George W},
  date = {1986},
  journaltitle = {ACM SIGCHI Bulletin},
  volume = {17},
  number = {4},
  pages = {16--23},
  abstract = {In many contexts, humans often represent their own *‘neighborhood” in great detail, yet only major landmarks further away. This suggests that such views (“fisheye views”) might be useful for the computer display of large information structures like programs, data bases, online text, etc. This paper explores fisheye views presenting, in turn, naturalistic studies, a general formalism, a specific instantiation, a resulting computer program, example displays and an evaluation.},
  langid = {english},
  file = {/Users/npiccolotto/Zotero/storage/E4CTDUIS/Furnas - 1986 - Generalized fisheye views.pdf}
}

@inproceedings{gladisch2013,
  title = {Navigation {{Recommendations}} for {{Exploring Hierarchical Graphs}}},
  booktitle = {Advances in {{Visual Computing}}},
  author = {Gladisch, Stefan and Schumann, Heidrun and Tominski, Christian},
  editor = {Bebis, George and Boyle, Richard and Parvin, Bahram and Koracin, Darko and Li, Baoxin and Porikli, Fatih and Zordan, Victor and Klosowski, James and Coquillart, Sabine and Luo, Xun and Chen, Min and Gotz, David},
  date = {2013},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  pages = {36--47},
  publisher = {{Springer}},
  location = {{Berlin, Heidelberg}},
  doi = {10.1007/978-3-642-41939-3_4},
  abstract = {Navigation is a key interaction when analyzing graphs by means of interactive visualization. Particularly for unknown graphs, the user often faces situations where it is not entirely clear where to go next. For hierarchical graphs, the user may also ponder whether it is useful to look at the data at a higher or lower level of abstraction.},
  isbn = {978-3-642-41939-3},
  langid = {english},
  keywords = {Exploration State,Graph Layout,Graph Visualization,Information Visualization,Partial View},
  file = {/Users/npiccolotto/Zotero/storage/4T6PT9QG/Gladisch et al. - 2013 - Navigation Recommendations for Exploring Hierarchi.pdf}
}

@inproceedings{hao2005,
  title = {Importance-Driven Visualization Layouts for Large Time Series Data},
  booktitle = {{{IEEE Symposium}} on {{Information Visualization}}, 2005. {{INFOVIS}} 2005.},
  author = {Hao, M.C. and Dayal, Umeshwar and Keim, D.A. and Schreck, T.},
  date = {2005-10},
  pages = {203--210},
  issn = {1522-404X},
  doi = {10.1109/INFVIS.2005.1532148},
  abstract = {Time series are an important type of data with applications in virtually every aspect of the real world. Often a large number of time series have to be monitored and analyzed in parallel. Sets of time series may show intrinsic hierarchical relationships and varying degrees of importance among the individual time series. Effective techniques for visually analyzing large sets of time series should encode the relative importance and hierarchical ordering of the time series data by size and position, and should also provide a high degree of regularity in order to support comparability by the analyst. In this paper, we present a framework for visualizing large sets of time series. Based on the notion of inter time series importance relationships, we define a set of objective functions that space-filling layout schemes for time series data should obey. We develop an efficient algorithm addressing the identified problems by generating layouts that reflect hierarchy and importance based relationships in a regular layout with favorable aspect ratios. We apply our technique to a number of real world data sets including sales and stock data, and we compare our technique with an aspect ratio aware variant of the well known TreeMap algorithm. The examples show the advantages and practical usefulness of our layout algorithm.},
  eventtitle = {{{IEEE Symposium}} on {{Information Visualization}}, 2005. {{INFOVIS}} 2005.},
  keywords = {Algorithm design and analysis,Chromium,Data visualization,Displays,Laboratories,Layout,Marketing and sales,Monitoring,Time series analysis,Tree graphs},
  file = {/Users/npiccolotto/Zotero/storage/HAV49SM4/Hao et al. - 2005 - Importance-driven visualization layouts for large .pdf;/Users/npiccolotto/Zotero/storage/PSFIRVEP/1532148.html}
}

@inproceedings{hauser2003,
  title = {Interactive {{Volume Visualization}} of {{Complex Flow Semantics}}},
  booktitle = {Proceedings of the 8th {{Fall Workshop}} on {{Vision}}, {{Modeling}} and {{Visualization}}},
  author = {Hauser, Helwig and Mlejnek, Matej},
  date = {2003},
  abstract = {Comprehending results from 3D CFD simulation is a difficult task. In this paper, we present a semantics-based approach to featurebased volume rendering of 3D flow data. We make use of interactive feature specification to acquire derived data about what is most interesting to the user. This process results in so-called degree-ofinterest (DOI) values, associated with the original data items. This information is then used during the visualization mapping to allow for visualization of flow semantics. We present three different approaches in this paper: (a) isosurfacing the degree of interest –the result is a triplet (or quintuplet) of iso-surfaces representing levels of interest; (b) feature volumes – volume rendering is used to depict 3D distributions of DOI values; and (c) interest-based seeding of streamlines, resulting in reduced clutter while focusing on the most interesting parts of the 3D flow. We utilize fast volume rendering (RTVR) for real-time viewing, also providing two-level volume rendering, which allows to seamlessly integrate all of the above-mentioned approaches.},
  eventtitle = {{{VMV}}},
  langid = {english},
  file = {/Users/npiccolotto/Zotero/storage/LEADVHBD/Hauser and Mlejnek - Interactive Volume Visualization of Complex Flow S.pdf}
}

@article{healey2012a,
  title = {Interest {{Driven Navigation}} in {{Visualization}}},
  author = {Healey, Christopher G. and Dennis, Brent M.},
  date = {2012-10},
  journaltitle = {IEEE Transactions on Visualization and Computer Graphics},
  volume = {18},
  number = {10},
  pages = {1744--1756},
  issn = {1941-0506},
  doi = {10.1109/TVCG.2012.23},
  abstract = {This paper describes a new method to explore and discover within a large data set. We apply techniques from preference elicitation to automatically identify data elements that are of potential interest to the viewer. These "elements of interest (EOI)” are bundled into spatially local clusters, and connected together to form a graph. The graph is used to build camera paths that allow viewers to "tour” areas of interest (AOI) within their data. It is also visualized to provide wayfinding cues. Our preference model uses Bayesian classification to tag elements in a data set as interesting or not interesting to the viewer. The model responds in real time, updating the elements of interest based on a viewer's actions. This allows us to track a viewer's interests as they change during exploration and analysis. Viewers can also interact directly with interest rules the preference model defines. We demonstrate our theoretical results by visualizing historical climatology data collected at locations throughout the world.},
  eventtitle = {{{IEEE Transactions}} on {{Visualization}} and {{Computer Graphics}}},
  keywords = {Bayesian methods,Bayesian network,Cameras,classification,Context awareness,Data models,Data visualization,navigation,Navigation,preferences,visualization.},
  file = {/Users/npiccolotto/Zotero/storage/QH6TXJ6G/Healey and Dennis - 2012 - Interest Driven Navigation in Visualization.pdf;/Users/npiccolotto/Zotero/storage/XV4B7RH9/stamp.html}
}

@inproceedings{heer2004,
  title = {{{DOITrees}} Revisited: Scalable, Space-Constrained Visualization of Hierarchical Data},
  shorttitle = {{{DOITrees}} Revisited},
  booktitle = {Proceedings of the Working Conference on {{Advanced}} Visual Interfaces},
  author = {Heer, Jeffrey and Card, Stuart K.},
  date = {2004-05-25},
  pages = {421--424},
  publisher = {{ACM}},
  location = {{Gallipoli Italy}},
  doi = {10.1145/989863.989941},
  url = {https://dl.acm.org/doi/10.1145/989863.989941},
  urldate = {2023-01-27},
  abstract = {This paper extends previous work on focus+context visualizations of tree-structured data, introducing an efficient, space-constrained, multi-focal tree layout algorithm (“TreeBlock”) and techniques at both the system and interactive levels for dealing with scale. These contributions are realized in a new version of the Degree-Of-Interest Tree browser, supporting real-time interactive visualization and exploration of data sets containing on the order of a million nodes.},
  eventtitle = {{{AVI04}}: {{International Conference}} on {{Advanced Visual Interfaces}}},
  isbn = {978-1-58113-867-2},
  langid = {english},
  file = {/Users/npiccolotto/Zotero/storage/QZJH6YVU/Heer and Card - 2004 - DOITrees revisited scalable, space-constrained vi.pdf}
}

@inproceedings{herman2000a,
  title = {Density Functions for Visual Attributes and Effective Partitioning in Graph Visualization},
  booktitle = {{{IEEE Symposium}} on {{Information Visualization}} 2000. {{INFOVIS}} 2000. {{Proceedings}}},
  author = {Herman, I. and Marshall, M.S. and Melancon, G.},
  date = {2000-10},
  pages = {49--56},
  issn = {1522-404X},
  doi = {10.1109/INFVIS.2000.885090},
  abstract = {Two tasks in graph visualization require partitioning: the assignment of visual attributes and divisive clustering. Often, we would like to assign a color or other visual attributes to a node or edge that indicates an associated value. In an application involving divisive clustering, we would like to partition the graph into subsets of graph elements based on metric values in such a way that all subsets are evenly populated. Assuming a uniform distribution of metric values during either partitioning or coloring can have undesired effects such as empty clusters or only one level of emphasis for the entire graph. Probability density functions derived from statistics about a metric can help systems succeed at these tasks.},
  eventtitle = {{{IEEE Symposium}} on {{Information Visualization}} 2000. {{INFOVIS}} 2000. {{Proceedings}}},
  keywords = {Application software,Chromium,Computer graphics,Data visualization,Mathematics,Navigation,Probability density function,Read only memory,Statistics,Tree graphs},
  file = {/Users/npiccolotto/Zotero/storage/QHJGSHZ4/Herman et al. - 2000 - Density functions for visual attributes and effect.pdf;/Users/npiccolotto/Zotero/storage/2M9E6GXU/stamp.html}
}

@inproceedings{husken2007,
  title = {Degree-of-{{Interest Visualization}} for {{Ontology Exploration}}},
  booktitle = {Human-{{Computer Interaction}} – {{INTERACT}} 2007},
  author = {Hüsken, Peter and Ziegler, Jürgen},
  editor = {Baranauskas, Cécilia and Palanque, Philippe and Abascal, Julio and Barbosa, Simone Diniz Junqueira},
  date = {2007},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  pages = {116--119},
  publisher = {{Springer}},
  location = {{Berlin, Heidelberg}},
  doi = {10.1007/978-3-540-74796-3_12},
  abstract = {In recent years, improvements in semantic web technologies have given us new expressive description languages for modeling knowledge domains — the so called ontologies. Nevertheless, ontology editors lack of easy and intuitive user interfaces, so that the exploration and creation of ontologies is often too difficult to be efficient. In this short paper, we introduce a new tree widget which utilizes sophisticated visualization and interaction features for ontology exploration and editing as a work in progress study. Due to space limitations we co+ncentrate here on the aspect of ontology browsing.},
  isbn = {978-3-540-74796-3},
  langid = {english},
  keywords = {Concept Selection,Intuitive User Interface,Object Property,Tree Layout,Tree Widget},
  file = {/Users/npiccolotto/Zotero/storage/DGZ74KHE/Hüsken and Ziegler - 2007 - Degree-of-Interest Visualization for Ontology Expl.pdf}
}

@article{keim1994,
  title = {{{VisDB}}: Database Exploration Using Multidimensional Visualization},
  shorttitle = {{{VisDB}}},
  author = {Keim, D.A. and Kriegel, H.-P.},
  date = {1994-09},
  journaltitle = {IEEE Computer Graphics and Applications},
  volume = {14},
  number = {5},
  pages = {40--49},
  issn = {1558-1756},
  doi = {10.1109/38.310723},
  abstract = {Discusses how the VisDB system supports the query specification process by representing the result visually. The main idea behind the system stems from the view of relational database tables as sets of multidimensional data where the number of attributes corresponds to the number of dimensions. In such a view, it is often unclear. In this system, each display pixel represents one database item. Pixels are arranged and colored to indicate the item's relevance to a user query and to give a visual impression of the resulting data set.{$<>$}},
  eventtitle = {{{IEEE Computer Graphics}} and {{Applications}}},
  keywords = {Computerized monitoring,Data engineering,Data visualization,Displays,Feedback,Multidimensional systems,Relational databases,Satellites,Sensor systems,Visual databases},
  file = {/Users/npiccolotto/Zotero/storage/NYXHISHA/Keim and Kriegel - 1994 - VisDB database exploration using multidimensional.pdf;/Users/npiccolotto/Zotero/storage/CGDCTRJT/310723.html}
}

@inproceedings{kersten2005,
  title = {Mylar: A Degree-of-Interest Model for {{IDEs}}},
  shorttitle = {Mylar},
  booktitle = {Proceedings of the 4th International Conference on {{Aspect-oriented}} Software Development},
  author = {Kersten, Mik and Murphy, Gail C.},
  date = {2005-03-14},
  pages = {159--168},
  publisher = {{ACM}},
  location = {{Chicago Illinois}},
  doi = {10.1145/1052898.1052912},
  url = {https://dl.acm.org/doi/10.1145/1052898.1052912},
  urldate = {2023-02-22},
  abstract = {Even when working on a well-modularized software system, programmers tend to spend more time navigating the code than working with it. This phenomenon arises because it is impossible to modularize the code for all tasks that occur over the lifetime of a system. We describe the use of a degree-of-interest (DOI) model to capture the task context of program elements scattered across a code base. The Mylar tool that we built encodes the DOI of program elements by monitoring the programmer’s activity, and displays the encoded DOI model in views of Java and AspectJ programs. We also present the results of a preliminary diary study in which professional programmers used Mylar for their daily work on enterprise-scale Java systems.},
  eventtitle = {{{AOSD05}}: 4th {{International Conference}} on {{Aspect-Oriented Software Development Conference}}},
  isbn = {978-1-59593-042-2},
  langid = {english},
  file = {/Users/npiccolotto/Zotero/storage/SJ8ERMNQ/Kersten and Murphy - 2005 - Mylar a degree-of-interest model for IDEs.pdf}
}

@article{kosara2002,
  title = {Focus+context Taken Literally},
  author = {Kosara, R. and Miksch, S. and Hauser, H.},
  date = {2002-01},
  journaltitle = {IEEE Computer Graphics and Applications},
  volume = {22},
  number = {1},
  pages = {22--29},
  issn = {1558-1756},
  doi = {10.1109/38.974515},
  abstract = {A common feature of information visualization applications, and also other areas, is to direct the user's attention to certain objects. This alerts users to a problem or shows the matching objects in response to a query. Often users also want to quickly understand the information pointed out in the context of the other information and not just see the results. This is one type of the focus+context (F+C) technique, which provides both detailed information of the currently most relevant objects, as well as giving users an idea of the context. The authors present a focus+context method that blurs objects based on their relevance (rather than distance) to direct the user's attention.},
  eventtitle = {{{IEEE Computer Graphics}} and {{Applications}}},
  keywords = {Cameras,Computer graphics,Data visualization,Displays,Focusing,Human factors,Lenses,Photography,Rubber,User interfaces},
  file = {/Users/npiccolotto/Zotero/storage/U9JHTS9U/Kosara et al. - 2002 - Focus+context taken literally.pdf;/Users/npiccolotto/Zotero/storage/P5HPHYKF/stamp.html}
}

@inproceedings{kosara2004,
  title = {Linking {{Scientiﬁc}} and {{Information Visualization}} with {{Interactive 3D Scatterplots}}},
  booktitle = {The 12-Th {{International Conference}} in {{Central Europe}} on {{Computer Graphics}}, {{Visualization}} and {{Computer Vision}} 2004},
  author = {Kosara, Robert and Sahling, Gerald N and Hauser, Helwig},
  date = {2004},
  pages = {133--140},
  eventtitle = {{{WSCG}} '2004: {{Short Communications}}},
  isbn = {80-903100-5-2},
  langid = {english},
  file = {/Users/npiccolotto/Zotero/storage/E56P2R2S/Kosara et al. - Linking Scientiﬁc and Information Visualization wi.pdf}
}

@article{lehmann2010a,
  title = {Interactive Visualization for Opportunistic Exploration of Large Document Collections},
  author = {Lehmann, Simon and Schwanecke, Ulrich and Dörner, Ralf},
  date = {2010-04-01},
  journaltitle = {Information Systems},
  shortjournal = {Information Systems},
  series = {Special {{Section}}: {{Context-Oriented Information Integration}}},
  volume = {35},
  number = {2},
  pages = {260--269},
  issn = {0306-4379},
  doi = {10.1016/j.is.2009.10.004},
  url = {https://www.sciencedirect.com/science/article/pii/S0306437909001021},
  urldate = {2023-01-27},
  abstract = {Finding relevant information in a large and comprehensive collection of cross-referenced documents like Wikipedia usually requires a quite accurate idea where to look for the pieces of data being sought. A user might not yet have enough domain-specific knowledge to form a precise search query to get the desired result on the first try. Another problem arises from the usually highly cross-referenced structure of such document collections. When researching a subject, users usually follow some references to get additional information not covered by a single document. With each document, more opportunities to navigate are added and the structure and relations of the visited documents gets harder to understand. This paper describes the interactive visualization Wivi which enables users to intuitively navigate Wikipedia by visualizing the structure of visited articles and emphasizing relevant other topics. Combining this visualization with a view of the current article results in a custom browser specially adapted for exploring large information networks. By visualizing the potential paths that could be taken, users are invited to read up on subjects relevant to the current point of focus and thus opportunistically finding relevant information. Results from a user study indicate that this visual navigation can be easily used and understood. A majority of the participants of the study stated that this method of exploration supports them finding information in Wikipedia.},
  langid = {english},
  keywords = {Browsing,Information visualization,Opportunistic exploration,Searching,Wikis},
  file = {/Users/npiccolotto/Zotero/storage/BMNKS2EC/Lehmann et al. - 2010 - Interactive visualization for opportunistic explor.pdf;/Users/npiccolotto/Zotero/storage/7UR7KTLC/S0306437909001021.html}
}

@inproceedings{masui1998,
  title = {{{LensBar-visualization}} for Browsing and Filtering Large Lists of Data},
  booktitle = {Proceedings {{IEEE Symposium}} on {{Information Visualization}} ({{Cat}}. {{No}}.{{98TB100258}})},
  author = {Masui, T.},
  date = {1998},
  pages = {113--120,},
  publisher = {{IEEE Comput. Soc}},
  location = {{Research Triangle, CA, USA}},
  doi = {10.1109/INFVIS.1998.729567},
  url = {http://ieeexplore.ieee.org/document/729567/},
  urldate = {2023-01-27},
  abstract = {We propose a simple and powerful graphical interface tool called the LensBar, for filtering and visualizing a large list of data. Browsing and querying are the most important techniques for information retrieval, and LensBar integrates the two techniques into a simplelooking scroll window with a slider. While it looks familiar to users of conventional graphical interface tools, its filtering and zooming mechanism offers sophisticated handling of large lists of text-oriented data.},
  eventtitle = {{{IEEE Symposium}} on {{Information Visualization}}},
  isbn = {978-0-8186-9093-8},
  langid = {english},
  file = {/Users/npiccolotto/Zotero/storage/9CNFA8JF/Masui - 1998 - LensBar-visualization for browsing and filtering l.pdf}
}

@article{muigg2008,
  title = {A {{Four-level Focus}}+{{Context Approach}} to {{Interactive Visual Analysis}} of {{Temporal Features}} in {{Large Scientific Data}}},
  author = {Muigg, Philipp and Kehrer, Johannes and Oeltze, Steffen and Piringer, Harald and Doleisch, Helmut and Preim, Bernhard and Hauser, Helwig},
  date = {2008},
  journaltitle = {Computer Graphics Forum},
  volume = {27},
  number = {3},
  pages = {775--782},
  issn = {1467-8659},
  doi = {10.1111/j.1467-8659.2008.01207.x},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1467-8659.2008.01207.x},
  urldate = {2019-12-10},
  abstract = {In this paper we present a new approach to the interactive visual analysis of time-dependent scientific data – both from measurements as well as from computational simulation – by visualizing a scalar function over time for each of tenthousands or even millions of sample points. In order to cope with overdrawing and cluttering, we introduce a new four-level method of focus+context visualization. Based on a setting of coordinated, multiple views (with linking and brushing), we integrate three different kinds of focus and also the context in every single view. Per data item we use three values (from the unit interval each) to represent to which degree the data item is part of the respective focus level. We present a color compositing scheme which is capable of expressing all three values in a meaningful way, taking semantics and their relations amongst each other (in the context of our multiple linked view setup) into account. Furthermore, we present additional image-based postprocessing methods to enhance the visualization of large sets of function graphs, including a texture-based technique based on line integral convolution (LIC). We also propose advanced brushing techniques which are specific to the time-dependent nature of the data (in order to brush patterns over time more efficiently). We demonstrate the usefulness of the new approach in the context of medical perfusion data.},
  langid = {english},
  file = {/Users/npiccolotto/Zotero/storage/U3I8SSDB/Muigg et al. - 2008 - A Four-level Focus+Context Approach to Interactive.pdf;/Users/npiccolotto/Zotero/storage/YTZHUEGT/j.1467-8659.2008.01207.html}
}

@article{nguyen2006,
  title = {A {{Novel Visualization Model}} for {{Web Search Results}}},
  author = {Nguyen, Tien and Zhang, Jin},
  date = {2006-09},
  journaltitle = {IEEE Transactions on Visualization and Computer Graphics},
  volume = {12},
  number = {5},
  pages = {981--988},
  issn = {1941-0506},
  doi = {10.1109/TVCG.2006.111},
  abstract = {This paper presents an interactive visualization system, named WebSearchViz, for visualizing the Web search results and facilitating users' navigation and exploration. The metaphor in our model is the solar system with its planets and asteroids revolving around the sun. Location, color, movement, and spatial distance of objects in the visual space are used to represent the semantic relationships between a query and relevant Web pages. Especially, the movement of objects and their speeds add a new dimension to the visual space, illustrating the degree of relevance among a query and Web search results in the context of users' subjects of interest. By interacting with the visual space, users are able to observe the semantic relevance between a query and a resulting Web page with respect to their subjects of interest, context information, or concern. Users' subjects of interest can be dynamically changed, redefined, added, or deleted from the visual space},
  eventtitle = {{{IEEE Transactions}} on {{Visualization}} and {{Computer Graphics}}},
  keywords = {Data visualization,Humans,movement,Navigation,Planets,Solar system,speed,Sun,Visual perception,Visualization model,Web pages,Web search,Web search results,Web sites},
  file = {/Users/npiccolotto/Zotero/storage/7CNRUP94/Nguyen and Zhang - 2006 - A Novel Visualization Model for Web Search Results.pdf;/Users/npiccolotto/Zotero/storage/4PTSLN7J/stamp.html}
}

@article{nobre2019a,
  title = {Juniper: {{A Tree}}+{{Table Approach}} to {{Multivariate Graph Visualization}}},
  shorttitle = {Juniper},
  author = {Nobre, Carolina and Streit, Marc and Lex, Alexander},
  date = {2019-01},
  journaltitle = {IEEE Transactions on Visualization and Computer Graphics},
  volume = {25},
  number = {1},
  pages = {544--554},
  issn = {1941-0506},
  doi = {10.1109/TVCG.2018.2865149},
  abstract = {Analyzing large, multivariate graphs is an important problem in many domains, yet such graphs are challenging to visualize. In this paper, we introduce a novel, scalable, tree-table multivariate graph visualization technique, which makes many tasks related to multivariate graph analysis easier to achieve. The core principle we follow is to selectively query for nodes or subgraphs of interest and visualize these subgraphs as a spanning tree of the graph. The tree is laid out linearly, which enables us to juxtapose the nodes with a table visualization where diverse attributes can be shown. We also use this table as an adjacency matrix, so that the resulting technique is a hybrid node-link/adjacency matrix technique. We implement this concept in Juniper and complement it with a set of interaction techniques that enable analysts to dynamically grow, restructure, and aggregate the tree, as well as change the layout or show paths between nodes. We demonstrate the utility of our tool in usage scenarios for different multivariate networks: a bipartite network of scholars, papers, and citation metrics and a multitype network of story characters, places, books, etc.},
  eventtitle = {{{IEEE Transactions}} on {{Visualization}} and {{Computer Graphics}}},
  keywords = {adjacency matrix,Data visualization,Encoding,Layout,Multivariate graphs,Network topology,networks,spanning trees,Task analysis,Topology,tree-based graph visualization,visualization,Visualization},
  file = {/Users/npiccolotto/Zotero/storage/JLPI268V/Nobre et al. - 2019 - Juniper A Tree+Table Approach to Multivariate Gra.pdf;/Users/npiccolotto/Zotero/storage/8YMCMXCS/stamp.html}
}

@inproceedings{noik1993,
  title = {Layout-Independent Fisheye Views of Nested Graphs},
  booktitle = {Proceedings 1993 {{IEEE Symposium}} on {{Visual Languages}}},
  author = {Noik, E.G.},
  date = {1993-08},
  pages = {336--341},
  doi = {10.1109/VL.1993.269620},
  abstract = {Although a graph can be a useful device for visualizing complex relationships, drawings of large graphs can be difficult to comprehend. As one remedy, we formulated a novel generalized approach for generating fisheye views of nested graphs with multiple variable focal points, and devised an algorithm that creates fisheye views in the absence of application specific distance metrics. Previous solutions produced fisheye views by filtering or distorting drawings of graphs. Since these approaches relied on geometric notions of distance, they could only be applied effectively in limited cases. By contrast, our approach treats fisheye view generation as a phase that precedes graph layout, rather than as a technique that alters an existing drawing, and does not suffer these drawbacks.{$<>$}},
  eventtitle = {Proceedings 1993 {{IEEE Symposium}} on {{Visual Languages}}},
  keywords = {Aircraft,Calendars,Computer displays,Information filtering,Information filters,Lenses,Sampling methods,Shape,Tree graphs,Visualization},
  file = {/Users/npiccolotto/Zotero/storage/BJKPNL6I/Noik - 1993 - Layout-independent fisheye views of nested graphs.pdf;/Users/npiccolotto/Zotero/storage/85A554UL/stamp.html}
}

@article{piccolotto2022a,
  title = {{{TBSSvis}}: {{Visual Analytics}} for {{Temporal Blind Source Separation}}},
  shorttitle = {{{TBSSvis}}},
  author = {Piccolotto, Nikolaus and Bögl, Markus and Gschwandtner, Theresia and Muehlmann, Christoph and Nordhausen, Klaus and Filzmoser, Peter and Miksch, Silvia},
  date = {2022},
  journaltitle = {Visual Informatics},
  volume = {6},
  number = {4},
  pages = {51--66},
  doi = {10.1016/j.visinf.2022.10.002},
  abstract = {Temporal Blind Source Separation (TBSS) is used to obtain the true, underlying processes from noisy temporal multivariate data, such as electrocardiograms. While these algorithms are widely used, the involved tasks are not well supported in current visualization tools, which offer only text-based interactions and static images. Analysts are limited in analyzing and comparing obtained results, which consist of diverse data such as matrices and ensembles of time series. Additionally, parameters have a big impact on separation performance, but as a consequence of improper tooling analysts currently do not consider the whole parameter space. We propose to solve these problems by applying visual analytics (VA) principles. To this end, we developed a task abstraction and visualization design in a user-centered design process. We present TBSSvis, an interactive web-based VA prototype, which we evaluated in two qualitative user studies. Feedback and observations from these studies show that TBSSvis supports the actual workflow and combination of interactive visualizations that facilitate the tasks involved in analyzing TBBS results. It also provides guidance to facilitate informed parameter selection and the analysis of the data at hand.},
  keywords = {Computer Science - Human-Computer Interaction,peer-reviewed},
  file = {/Users/npiccolotto/Zotero/storage/JCJMV22A/Piccolotto et al. - 2022 - TBSSvis Visual Analytics for Temporal Blind Sourc.pdf}
}

@inproceedings{rao1994a,
  title = {The Table Lens: Merging Graphical and Symbolic Representations in an Interactive Focus + Context Visualization for Tabular Information},
  shorttitle = {The Table Lens},
  booktitle = {Proceedings of the {{SIGCHI}} Conference on {{Human}} Factors in Computing Systems Celebrating Interdependence - {{CHI}} '94},
  author = {Rao, Ramana and Card, Stuart K.},
  date = {1994},
  pages = {318--322},
  publisher = {{ACM Press}},
  location = {{Boston, Massachusetts, United States}},
  doi = {10.1145/191666.191776},
  url = {http://portal.acm.org/citation.cfm?doid=191666.191776},
  urldate = {2023-02-17},
  eventtitle = {The {{SIGCHI}} Conference},
  isbn = {978-0-89791-650-9},
  langid = {english},
  file = {/Users/npiccolotto/Zotero/storage/DERFLTHE/191666.pdf}
}

@inproceedings{sarkar1992,
  title = {Graphical Fisheye Views of Graphs},
  booktitle = {Proceedings of the {{SIGCHI}} Conference on {{Human}} Factors in Computing Systems  - {{CHI}} '92},
  author = {Sarkar, Manojit and Brown, Marc H.},
  date = {1992},
  pages = {83--91},
  publisher = {{ACM Press}},
  location = {{Monterey, California, United States}},
  doi = {10.1145/142750.142763},
  url = {http://portal.acm.org/citation.cfm?doid=142750.142763},
  urldate = {2023-02-17},
  abstract = {A jlsheye lens is a very wide angle lens that shows places nearby in detail while also showing remote regions in successively less detail. This paper describes a system for viewing and browsing planar graphs using a software analog of a fisheye lens. We first show how to implement such a view using solely geometric transformations. Wc then describe a more general transformation that allows hierarchical, structured information about the graph to modify the views. Our general transformation is a fundamental extension to the previous research in fisheye views.},
  eventtitle = {The {{SIGCHI}} Conference},
  isbn = {978-0-89791-513-7},
  langid = {english},
  file = {/Users/npiccolotto/Zotero/storage/J2EAB9RS/Sarkar and Brown - 1992 - Graphical fisheye views of graphs.pdf}
}

@article{stitz2016c,
  title = {{{AVOCADO}}: {{Visualization}} of {{Workflow}}–{{Derived Data Provenance}} for {{Reproducible Biomedical Research}}},
  shorttitle = {{{AVOCADO}}},
  author = {Stitz, H. and Luger, S. and Streit, M. and Gehlenborg, N.},
  date = {2016-06},
  journaltitle = {Computer Graphics Forum},
  shortjournal = {Computer Graphics Forum},
  volume = {35},
  number = {3},
  pages = {481--490},
  issn = {0167-7055, 1467-8659},
  doi = {10.1111/cgf.12924},
  url = {https://onlinelibrary.wiley.com/doi/10.1111/cgf.12924},
  urldate = {2023-01-27},
  abstract = {A major challenge in data-driven biomedical research lies in the collection and representation of data provenance information to ensure that findings are reproducibile. In order to communicate and reproduce multi-step analysis workflows executed on datasets that contain data for dozens or hundreds of samples, it is crucial to be able to visualize the provenance graph at different levels of aggregation. Most existing approaches are based on node-link diagrams, which do not scale to the complexity of typical data provenance graphs. In our proposed approach, we reduce the complexity of the graph using hierarchical and motif-based aggregation. Based on user action and graph attributes, a modular degree-of-interest (DoI) function is applied to expand parts of the graph that are relevant to the user. This interest-driven adaptive approach to provenance visualization allows users to review and communicate complex multi-step analyses, which can be based on hundreds of files that are processed by numerous workflows. We have integrated our approach into an analysis platform that captures extensive data provenance information, and demonstrate its effectiveness by means of a biomedical usage scenario.},
  langid = {english},
  file = {/Users/npiccolotto/Zotero/storage/9QWK8BK2/Stitz et al. - 2016 - AVOCADO Visualization of Workflow–Derived Data Pr.pdf}
}

@inproceedings{vanham2004,
  title = {Interactive {{Visualization}} of {{Small World Graphs}}},
  booktitle = {{{IEEE Symposium}} on {{Information Visualization}}},
  author = {van Ham, F. and van Wijk, J.J.},
  options = {useprefix=true},
  date = {2004-10},
  pages = {199--206},
  issn = {1522-404X},
  doi = {10.1109/INFVIS.2004.43},
  abstract = {Many real world graphs have small world characteristics, that is, they have a small diameter compared to the number of nodes and exhibit a local cluster structure. Examples are social networks, software structures, bibliographic references and biological neural nets. Their high connectivity makes both finding a pleasing layout and a suitable clustering hard. In this paper we present a method to create scalable, interactive visualizations of small world graphs, allowing the user to inspect local clusters while maintaining a global overview of the entire structure. The visualization method uses a combination of both semantical and geometrical distortions, while the layout is generated by a spring embedder algorithm using recently developed force model. We use a cross referenced database of 500 artists as a running example},
  eventtitle = {{{IEEE Symposium}} on {{Information Visualization}}},
  keywords = {Clustering,Clustering algorithms,Computer science,Graph Drawing,Graph Visualization,Mathematics,Neural networks,Small World Graphs,Social network services,Solid modeling,Spatial databases,Springs,Visual databases,Visualization},
  file = {/Users/npiccolotto/Zotero/storage/UM725FJ2/van Ham and van Wijk - 2004 - Interactive Visualization of Small World Graphs.pdf;/Users/npiccolotto/Zotero/storage/UPY9IR9H/stamp.html}
}

@article{vanham2009,
  title = {“{{Search}}, {{Show Context}}, {{Expand}} on {{Demand}}”: {{Supporting Large Graph Exploration}} with {{Degree-of-Interest}}},
  shorttitle = {“{{Search}}, {{Show Context}}, {{Expand}} on {{Demand}}”},
  author = {van Ham, Frank and Perer, Adam},
  options = {useprefix=true},
  date = {2009-11},
  journaltitle = {IEEE Transactions on Visualization and Computer Graphics},
  volume = {15},
  number = {6},
  pages = {953--960},
  issn = {1941-0506},
  doi = {10.1109/TVCG.2009.108},
  abstract = {A common goal in graph visualization research is the design of novel techniques for displaying an overview of an entire graph. However, there are many situations where such an overview is not relevant or practical for users, as analyzing the global structure may not be related to the main task of the users that have semi-specific information needs. Furthermore, users accessing large graph databases through an online connection or users running on less powerful (mobile) hardware simply do not have the resources needed to compute these overviews. In this paper, we advocate an interaction model that allows users to remotely browse the immediate context graph around a specific node of interest. We show how Furnas’ original degree of interest function can be adapted from trees to graphs and how we can use this metric to extract useful contextual subgraphs, control the complexity of the generated visualization and direct users to interesting datapoints in the context. We demeffectiveness of our approach with an exploration of a dense online database containing over 3 million legal citations.},
  eventtitle = {{{IEEE Transactions}} on {{Visualization}} and {{Computer Graphics}}},
  keywords = {Context modeling,Data analysis,Data visualization,degree of interest,focus+context,Graph visualization,Hardware,Information analysis,Law,legal citation networks,Legal factors,Mobile computing,network visualization,Tree graphs,Visual databases},
  file = {/Users/npiccolotto/Zotero/storage/DJJQYKC8/van Ham and Perer - 2009 - “Search, Show Context, Expand on Demand” Supporti.pdf;/Users/npiccolotto/Zotero/storage/WG3HLWAL/stamp.html}
}

@article{viola2005,
  title = {Importance-Driven Feature Enhancement in Volume Visualization},
  author = {Viola, I. and Kanitsar, A. and Groller, M.E.},
  date = {2005-07},
  journaltitle = {IEEE Transactions on Visualization and Computer Graphics},
  volume = {11},
  number = {4},
  pages = {408--418},
  issn = {1941-0506},
  doi = {10.1109/TVCG.2005.62},
  abstract = {This paper presents importance-driven feature enhancement as a technique for the automatic generation of cut-away and ghosted views out of volumetric data. The presented focus+context approach removes or suppresses less important parts of a scene to reveal more important underlying information. However, less important parts are fully visible in those regions, where important visual information is not lost, i.e., more relevant features are not occluded. Features within the volumetric data are first classified according to a new dimension, denoted as object importance. This property determines which structures should be readily discernible and which structures are less important. Next, for each feature, various representations (levels of sparseness) from a dense to a sparse depiction are defined. Levels of sparseness define a spectrum of optical properties or rendering styles. The resulting image is generated by ray-casting and combining the intersected features proportional to their importance (importance compositing). The paper includes an extended discussion on several possible schemes for levels of sparseness specification. Furthermore, different approaches to importance compositing are treated.},
  eventtitle = {{{IEEE Transactions}} on {{Visualization}} and {{Computer Graphics}}},
  keywords = {Biomedical imaging,Biomedical optical imaging,Data visualization,focus+context techniques,Focusing,illustrative techniques.,Index Terms- View-dependent visualization,Layout,Lesions,level-of-detail techniques,Liver neoplasms,Medical diagnostic imaging,Rendering (computer graphics),Shape,volume rendering},
  file = {/Users/npiccolotto/Zotero/storage/M5HK7XFI/Viola et al. - 2005 - Importance-driven feature enhancement in volume vi.pdf;/Users/npiccolotto/Zotero/storage/S8FP3TUR/stamp.html}
}

@article{wang2011a,
  title = {Feature-{{Preserving Volume Data Reduction}} and {{Focus}}+{{Context Visualization}}},
  author = {Wang, Yu-Shuen and Wang, Chaoli and Lee, Tong-Yee and Ma, Kwan-Liu},
  date = {2011-02},
  journaltitle = {IEEE Transactions on Visualization and Computer Graphics},
  volume = {17},
  number = {2},
  pages = {171--181},
  issn = {1941-0506},
  doi = {10.1109/TVCG.2010.34},
  abstract = {The growing sizes of volumetric data sets pose a great challenge for interactive visualization. In this paper, we present a feature-preserving data reduction and focus+context visualization method based on transfer function driven, continuous voxel repositioning and resampling techniques. Rendering reduced data can enhance interactivity. Focus+context visualization can show details of selected features in context on display devices with limited resolution. Our method utilizes the input transfer function to assign importance values to regularly partitioned regions of the volume data. According to user interaction, it can then magnify regions corresponding to the features of interest while compressing the rest by deforming the 3D mesh. The level of data reduction achieved is significant enough to improve overall efficiency. By using continuous deformation, our method avoids the need to smooth the transition between low and high-resolution regions as often required by multiresolution methods. Furthermore, it is particularly attractive for focus+context visualization of multiple features. We demonstrate the effectiveness and efficiency of our method with several volume data sets from medical applications and scientific simulations.},
  eventtitle = {{{IEEE Transactions}} on {{Visualization}} and {{Computer Graphics}}},
  keywords = {Biomedical equipment,Chaos,Costs,Data reduction,Data visualization,Displays,Energy resolution,focus+context visualization,interactive visualization,Medical services,Medical simulation,mesh deformation,Runtime,transfer functions,Transfer functions,volume rendering.},
  file = {/Users/npiccolotto/Zotero/storage/KBG3FHLN/Wang et al. - 2011 - Feature-Preserving Volume Data Reduction and Focus.pdf;/Users/npiccolotto/Zotero/storage/LPFPSBEX/stamp.html}
}

@inproceedings{ward1994,
  title = {{{XmdvTool}}: Integrating Multiple Methods for Visualizing Multivariate Data},
  shorttitle = {{{XmdvTool}}},
  booktitle = {Proceedings {{Visualization}} '94},
  author = {Ward, M.O.},
  date = {1994-10},
  pages = {326--333},
  doi = {10.1109/VISUAL.1994.346302},
  abstract = {Much of the attention in visualization research has focussed on data rooted in physical phenomena, which is generally limited to three or four dimensions. However, many sources of data do not share this dimensional restriction. A critical problem in the analysis of such data is providing researchers with tools to gain insights into characteristics of the data, such as anomalies and patterns. Several visualization methods have been developed to address this problem, and each has its strengths and weaknesses. This paper describes a system named XmdvTool which integrates several of the most common methods for projecting multivariate data onto a two-dimensional screen. This integration allows users to explore their data in a variety of formats with ease. A view enhancement mechanism called an N-dimensional brush is also described. The brush allows users to gain insights into spatial relationships over N dimensions by highlighting data which falls within a user-specified subspace.{$<>$}},
  eventtitle = {Proceedings {{Visualization}} '94},
  keywords = {Brushes,Computer science,Data analysis,Data visualization,Degradation,Displays,Pattern analysis},
  file = {/Users/npiccolotto/Zotero/storage/V8FP9ERF/Ward - 1994 - XmdvTool integrating multiple methods for visuali.pdf;/Users/npiccolotto/Zotero/storage/LNSSVWBR/stamp.html}
}

@article{wu2013a,
  title = {{{ViSizer}}: {{A Visualization Resizing Framework}}},
  shorttitle = {{{ViSizer}}},
  author = {Wu, Yingcai and Liu, Xiaotong and Liu, Shixia and Ma, Kwan-Liu},
  date = {2013-02},
  journaltitle = {IEEE Transactions on Visualization and Computer Graphics},
  volume = {19},
  number = {2},
  pages = {278--290},
  issn = {1941-0506},
  doi = {10.1109/TVCG.2012.114},
  abstract = {Visualization resizing is useful for many applications where users may use different display devices. General resizing techniques (e.g., uniform scaling) and image-resizing techniques suffer from several drawbacks, as they do not consider the content of the visualizations. This work introduces ViSizer, a perception-based framework for automatically resizing a visualization to fit any display. We formulate an energy function based on a perception model (feature congestion), which aims to determine the optimal deformation for every local region. We subsequently transform the problem into an optimization problem by the energy function. An efficient algorithm is introduced to iteratively solve the problem, allowing for automatic visualization resizing.},
  eventtitle = {{{IEEE Transactions}} on {{Visualization}} and {{Computer Graphics}}},
  keywords = {Clutter,Context,Data visualization,Ellipsoids,focus+context,Layout,nonlinear least squares optimization,Optimization,perception,Resizing,Visualization,visualization framework},
  file = {/Users/npiccolotto/Zotero/storage/D5T5GIQ7/Wu et al. - 2013 - ViSizer A Visualization Resizing Framework.pdf;/Users/npiccolotto/Zotero/storage/96VNZXVD/stamp.html}
}

@article{yang2021c,
  title = {Interactive {{Steering}} of {{Hierarchical Clustering}}},
  author = {Yang, Weikai and Wang, Xiting and Lu, Jie and Dou, Wenwen and Liu, Shixia},
  date = {2021-10},
  journaltitle = {IEEE Transactions on Visualization and Computer Graphics},
  volume = {27},
  number = {10},
  pages = {3953--3967},
  issn = {1941-0506},
  doi = {10.1109/TVCG.2020.2995100},
  abstract = {Hierarchical clustering is an important technique to organize big data for exploratory data analysis. However, existing one-size-fits-all hierarchical clustering methods often fail to meet the diverse needs of different users. To address this challenge, we present an interactive steering method to visually supervise constrained hierarchical clustering by utilizing both public knowledge (e.g., Wikipedia) and private knowledge from users. The novelty of our approach includes 1) automatically constructing constraints for hierarchical clustering using knowledge (knowledge-driven) and intrinsic data distribution (data-driven), and 2) enabling the interactive steering of clustering through a visual interface (user-driven). Our method first maps each data item to the most relevant items in a knowledge base. An initial constraint tree is then extracted using the ant colony optimization algorithm. The algorithm balances the tree width and depth and covers the data items with high confidence. Given the constraint tree, the data items are hierarchically clustered using evolutionary Bayesian rose tree. To clearly convey the hierarchical clustering results, an uncertainty-aware tree visualization has been developed to enable users to quickly locate the most uncertain sub-hierarchies and interactively improve them. The quantitative evaluation and case study demonstrate that the proposed approach facilitates the building of customized clustering trees in an efficient and effective manner.},
  eventtitle = {{{IEEE Transactions}} on {{Visualization}} and {{Computer Graphics}}},
  keywords = {Bayes methods,Buildings,Clustering algorithms,Clustering methods,constrained clustering,Data visualization,exploratory data analysis,Hierarchical clustering,Measurement,tree visualization,Visualization},
  file = {/Users/npiccolotto/Zotero/storage/TRHGBY45/Yang et al. - 2021 - Interactive Steering of Hierarchical Clustering.pdf;/Users/npiccolotto/Zotero/storage/7NC8W8PF/stamp.html}
}
